{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Using Spark Streaming to analyze tweets from Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully streamed tweets into your Kafka topic \"twitterstream\", we will explore using [Spark Streaming](http://spark.apache.org/streaming/) to analyze these tweets. Spark Streaming is a Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. \n",
    "\n",
    "![](http://spark.apache.org/docs/1.6.2/img/streaming-arch.png)\n",
    "([img src](http://spark.apache.org/docs/latest/streaming-programming-guide.html))\n",
    "\n",
    "In this lab, you will ingest the tweets from Kafka as a data source and the results published within this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Environment\n",
    "\n",
    "The code below ensures that the packages needed to run this lab are available to Spark. \n",
    "\n",
    "To run the code in Jupyter, you can put the cursor in each cell and press Shift-Enter to run it each cell at a time -- or you can use menu option `Kernel` -> `Restart & Run All`. When a cell is executing you'll see a `[*]` next to it, and once the execution is complete this changes to `[y]` where `y` is execution step number. Any output from that step will be shown immediately below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'\n",
    "\n",
    "import findspark\n",
    "findspark.init('/usr/lib/spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies\n",
    "\n",
    "We need to import the necessary pySpark modules for Spark, Spark Streaming, and Spark Streaming with Kafka. We also need the python `json` module for parsing the inbound twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    Spark\n",
    "from pyspark import SparkContext\n",
    "#    Spark Streaming\n",
    "from pyspark.streaming import StreamingContext\n",
    "#    Kafka\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "#    json parsing\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark and Streaming Context\n",
    "\n",
    "A Spark Context is the main entry point to connect to a Spark cluster and allows for the creation of RDDs, accumulators and broadcast variables. Note that only one SparkContext may be active per Java Virtual Machine (JVM) and you must terminate the active Spark context before creating a new one. the primary object under which everything else is called.\n",
    "\n",
    "A Streaming Context is built on top of a Spark Context and used to access functionalities of Spark Streaming, an extension of the core Spark API that enables the scalable, high-throughput, fault-tolerant stream processing of live data streams.  \n",
    "\n",
    "See the [API reference](http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext) and [programming guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html#initializing-streamingcontext) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Spark Context\n",
    "sc = SparkContext()\n",
    "\n",
    "# Create Streaming Context\n",
    "# The first argument is the Spark Context whilst the second argument represents the batch duration, which we set as 30 seconds here.\n",
    "ssc = StreamingContext(sc, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Discretized Stream (DStream) and connect to Kafka\n",
    "\n",
    "A DStream is the basic abstraction in Spark Streaming which consists of a continuous sequence of RDDs representing a continuous stream of data. The code below uses the native Spark Streaming Kafka capabilities to receive data from Kafka by connecting to a particular topic, twitterstream, which we created earlier on in this lab. Note that spark-streaming is an arbitrary name for a consumer group and can be changed.\n",
    "\n",
    "For more information see the [documentation](http://spark.apache.org/docs/latest/streaming-kafka-0-8-integration.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DStream from a Kafka topic\n",
    "kafkaStream = KafkaUtils.createStream(ssc, 'localhost:2181', 'spark-streaming', {'twitterstream':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the inbound message as json\n",
    "\n",
    "The inbound stream is a [`DStream`](http://spark.apache.org/docs/2.0.0/api/python/pyspark.streaming.html#pyspark.streaming.DStream), which supports various built-in [transformations](http://spark.apache.org/docs/latest/streaming-programming-guide.html#transformations-on-dstreams) such as `map` which is used here to parse the inbound messages from their native JSON format. \n",
    "\n",
    "Note that this will fail horribly if the inbound message _isn't_ valid JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed = kafkaStream.map(lambda v: json.loads(v[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of tweets in the batch\n",
    "\n",
    "The [`DStream`](http://spark.apache.org/docs/2.0.0/api/python/pyspark.streaming.html#pyspark.streaming.DStream) object provides native functions to count the number of messages in the batch, and to print them to the output: \n",
    "\n",
    "* [`count`](http://spark.apache.org/docs/2.0.0/api/python/pyspark.streaming.html#pyspark.streaming.DStream.count)\n",
    "* [`pprint`](http://spark.apache.org/docs/2.0.0/api/python/pyspark.streaming.html#pyspark.streaming.DStream.pprint) \n",
    "\n",
    "We use the `map` function to add in some text explaining the value printed. \n",
    "\n",
    "_Note that nothing gets written to output from the Spark Streaming context and descendent objects until the Spark Streaming Context is started, which happens later in the code_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed.count().map(lambda x:'Tweets in this batch: %s' % x).pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Author name from each tweet\n",
    "\n",
    "Tweets come through in a JSON structure, of which you can see an [example here](https://gist.github.com/rmoff/3968605712f437a1f37e7be52129cade). We're going to analyse tweets by author, which is accessible in the json structure at `user.screen_name`. \n",
    "\n",
    "The [`lambda`](https://pythonconquerstheuniverse.wordpress.com/2011/08/29/lambda_tutorial/) anonymous function is used to apply the `map` to each RDD within the DStream. The result is a DStream holding just the author's screenname for each tweet in the original DStream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToJson(x):\n",
    "    x = json.loads(x)\n",
    "    return x['user']['screen_name']\n",
    "\n",
    "authors_dstream = parsed.map(convertToJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of tweets per author\n",
    "\n",
    "With our authors DStream, we can now count them using the `countByValue` function. This is conceptually the same as this quasi-SQL statement: \n",
    "\n",
    "    SELECT   AUTHOR, COUNT(*)\n",
    "    FROM     DSTREAM\n",
    "    GROUP BY AUTHOR\n",
    "\n",
    "_Using `countByValue` is a more legible way of doing the same thing that you'll see done in tutorials elsewhere with a map / reduceBy. _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_counts = authors_dstream.countByValue()\n",
    "author_counts.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the most common words in the tweets\n",
    "\n",
    "The code below implements a word count for the tweets within the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findCommonWords(x):\n",
    "    x = json.loads(x)\n",
    "    return x['text'].split(\" \")\n",
    "\n",
    "parsed.\\\n",
    "    flatMap(findCommonWords)\\\n",
    "    .countByValue()\\\n",
    "    .transform\\\n",
    "      (lambda rdd:rdd.sortBy(lambda x:-x[1]))\\\n",
    "    .pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the streaming context\n",
    "\n",
    "As mentioned above, it is only after starting the Streaming Context where you will the results from the pprint functions. This is because all the code above is on defining the DStream only but not executed.\n",
    "\n",
    "You can add a awaitTermination to cancel the execution after a certain time, which in this case we have specified as 5 minutes.\n",
    "\n",
    "Wait for a while after you run the code below and if you see some results (i.e. number of tweets, author and word count for each batch), it means that you are successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:30:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 223\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:30:30\n",
      "-------------------------------------------\n",
      "('Miss_Kaye', 1)\n",
      "('bibacus', 1)\n",
      "('KateKathleen2', 1)\n",
      "('allyspeirs', 1)\n",
      "('ChLee5895', 1)\n",
      "('Maadu_In_Danger', 1)\n",
      "('liskaaz', 1)\n",
      "('JamesSandiford2', 1)\n",
      "('buddapapatdc', 1)\n",
      "('triciaking73', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:30:30\n",
      "-------------------------------------------\n",
      "('RT', 161)\n",
      "('to', 109)\n",
      "('the', 71)\n",
      "('health', 64)\n",
      "('a', 51)\n",
      "('', 43)\n",
      "('Board', 40)\n",
      "('in', 38)\n",
      "('Favorite', 38)\n",
      "('|', 38)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 314\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:00\n",
      "-------------------------------------------\n",
      "('isabelpennefat3', 1)\n",
      "('KhaledAlAmiri', 1)\n",
      "('winysouza', 1)\n",
      "('chancrosby', 1)\n",
      "('YoliIsTheBest', 1)\n",
      "('thiwillbedone', 1)\n",
      "('stayfitbefitt', 1)\n",
      "('neyruthooca1977', 1)\n",
      "('lilkellbell', 1)\n",
      "('healthyyfi', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:00\n",
      "-------------------------------------------\n",
      "('RT', 227)\n",
      "('to', 158)\n",
      "('the', 102)\n",
      "('health', 83)\n",
      "('a', 75)\n",
      "('is', 65)\n",
      "('and', 60)\n",
      "('of', 59)\n",
      "('Board', 54)\n",
      "('Up', 52)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 329\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:30\n",
      "-------------------------------------------\n",
      "('misty9220', 1)\n",
      "('ciel_angenoir', 1)\n",
      "('GtruckenRachel', 1)\n",
      "('kory_james93', 1)\n",
      "('Renea_Siler', 1)\n",
      "('fullyabstract', 1)\n",
      "('RuffShenanigans', 1)\n",
      "('wo_ai_zhongguo', 1)\n",
      "('adedejimeiry', 1)\n",
      "('sentientview', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:31:30\n",
      "-------------------------------------------\n",
      "('RT', 222)\n",
      "('to', 180)\n",
      "('a', 131)\n",
      "('the', 123)\n",
      "('health', 99)\n",
      "('with', 85)\n",
      "('The', 69)\n",
      "('of', 63)\n",
      "('is', 57)\n",
      "('care', 54)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 339\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:00\n",
      "-------------------------------------------\n",
      "('TheRebelPatient', 1)\n",
      "('TerryHubbard2', 1)\n",
      "('MangusColorado', 1)\n",
      "('lafforfact', 1)\n",
      "('beth_webber', 1)\n",
      "('mbutton47', 1)\n",
      "('Earth29839452', 1)\n",
      "('c4rmenge', 1)\n",
      "('FilthyDonald', 1)\n",
      "('DishMurphy', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:00\n",
      "-------------------------------------------\n",
      "('RT', 271)\n",
      "('to', 179)\n",
      "('the', 135)\n",
      "('a', 130)\n",
      "('for', 99)\n",
      "('health', 92)\n",
      "('', 79)\n",
      "('and', 73)\n",
      "('your', 67)\n",
      "('is', 65)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 341\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:30\n",
      "-------------------------------------------\n",
      "('Gospel1957', 1)\n",
      "('panocic13', 1)\n",
      "('loyce_cathey', 1)\n",
      "('pridefulove', 1)\n",
      "('yoboseiyo', 1)\n",
      "('TheMOGirl1', 1)\n",
      "('CCBauer28', 1)\n",
      "('deboraherhodes', 1)\n",
      "('Egnr8', 1)\n",
      "('Nellyy71', 2)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:32:30\n",
      "-------------------------------------------\n",
      "('RT', 224)\n",
      "('to', 158)\n",
      "('a', 151)\n",
      "('with', 104)\n",
      "('the', 102)\n",
      "('health', 96)\n",
      "('for', 85)\n",
      "('The', 78)\n",
      "('|', 76)\n",
      "('and', 76)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:33:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 275\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:33:00\n",
      "-------------------------------------------\n",
      "('TenneyNaumer', 1)\n",
      "('itsjustdylan23', 1)\n",
      "('jfaguayodiaz1', 1)\n",
      "('JoanLinbeck', 1)\n",
      "('Colindelays', 1)\n",
      "('nedryun', 1)\n",
      "('Debolex', 1)\n",
      "('1ideaatatime', 1)\n",
      "('lightbird_aka', 1)\n",
      "('stickerdujour', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:33:00\n",
      "-------------------------------------------\n",
      "('RT', 199)\n",
      "('the', 133)\n",
      "('to', 132)\n",
      "('', 98)\n",
      "('a', 94)\n",
      "('health', 93)\n",
      "('is', 67)\n",
      "('of', 65)\n",
      "('care', 53)\n",
      "('in', 49)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 227\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:00\n",
      "-------------------------------------------\n",
      "('minakngs', 1)\n",
      "('VickiJJustin', 1)\n",
      "('chrs1968', 1)\n",
      "('bookmarvel', 1)\n",
      "('Super_kpopfan', 1)\n",
      "('pkimbledidi', 1)\n",
      "('Ktboudreaux17', 1)\n",
      "('Chrissercdp', 1)\n",
      "('TNationMessHall', 1)\n",
      "('boser_j', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:00\n",
      "-------------------------------------------\n",
      "('RT', 163)\n",
      "('the', 124)\n",
      "('to', 100)\n",
      "('health', 86)\n",
      "('a', 78)\n",
      "('is', 64)\n",
      "('of', 55)\n",
      "('care', 50)\n",
      "('in', 49)\n",
      "('', 44)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 264\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:30\n",
      "-------------------------------------------\n",
      "('98s5041', 1)\n",
      "('Brookslei', 1)\n",
      "('VeraTweed', 1)\n",
      "('AlisonCarrick1', 1)\n",
      "('MKROHB', 1)\n",
      "('frqnttraveler', 1)\n",
      "('RaysRallyKrewe', 1)\n",
      "('yoboseiyo', 1)\n",
      "('worldsworstemo', 1)\n",
      "('NealIshshah89', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:34:30\n",
      "-------------------------------------------\n",
      "('RT', 166)\n",
      "('to', 130)\n",
      "('a', 125)\n",
      "('the', 116)\n",
      "('with', 95)\n",
      "('health', 88)\n",
      "('The', 74)\n",
      "('you', 67)\n",
      "('is', 59)\n",
      "('', 55)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 222\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:00\n",
      "-------------------------------------------\n",
      "('FL_Dentistry', 1)\n",
      "('25yearoldsenior', 1)\n",
      "('HotelFoxtrot', 1)\n",
      "('KhaledElawadi', 1)\n",
      "('brainchatbot', 1)\n",
      "('tobi_mide', 1)\n",
      "('lr_chenault', 1)\n",
      "('mydoggigi', 1)\n",
      "('detroitmagpie', 1)\n",
      "('siko_tcs', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:00\n",
      "-------------------------------------------\n",
      "('RT', 153)\n",
      "('the', 105)\n",
      "('to', 104)\n",
      "('health', 88)\n",
      "('a', 76)\n",
      "('of', 67)\n",
      "('is', 57)\n",
      "('', 56)\n",
      "('in', 54)\n",
      "('care', 40)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 307\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:30\n",
      "-------------------------------------------\n",
      "('GoldCoastBlog', 1)\n",
      "('DiannaCard', 1)\n",
      "('cookingscarlet', 1)\n",
      "('LabourLeft', 1)\n",
      "('Claudia00055931', 1)\n",
      "('JeanneBellCP', 1)\n",
      "('lawincorrupt', 1)\n",
      "('rosecolouredgay', 1)\n",
      "('hsbarrus', 1)\n",
      "('RitonKhan', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:35:30\n",
      "-------------------------------------------\n",
      "('RT', 176)\n",
      "('to', 120)\n",
      "('the', 120)\n",
      "('health', 109)\n",
      "('a', 102)\n",
      "('with', 77)\n",
      "('', 70)\n",
      "('of', 64)\n",
      "('is', 63)\n",
      "('The', 60)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:00\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 215\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:00\n",
      "-------------------------------------------\n",
      "('orgainkorgain', 1)\n",
      "('GGeryz1', 1)\n",
      "('LoriMar84543222', 1)\n",
      "('_Pinback', 1)\n",
      "('melissa137_505', 1)\n",
      "('mackee82', 1)\n",
      "('gailleyyyyy', 1)\n",
      "('megansnakebite', 2)\n",
      "('MasterThicc', 1)\n",
      "('jmh0011', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:00\n",
      "-------------------------------------------\n",
      "('RT', 162)\n",
      "('to', 128)\n",
      "('the', 113)\n",
      "('health', 89)\n",
      "('a', 73)\n",
      "('in', 57)\n",
      "('is', 57)\n",
      "('care', 57)\n",
      "('of', 54)\n",
      "('', 50)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:30\n",
      "-------------------------------------------\n",
      "Tweets in this batch: 259\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:30\n",
      "-------------------------------------------\n",
      "('avengergirl88', 1)\n",
      "('europabridge1', 1)\n",
      "('boofontheloose', 1)\n",
      "('ThePuckBeast', 1)\n",
      "('tristamac', 1)\n",
      "('glane2007', 1)\n",
      "('priceless_em', 1)\n",
      "('LwCureton2', 1)\n",
      "('marrybrownoo', 1)\n",
      "('LucidBrake', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-07-03 22:36:30\n",
      "-------------------------------------------\n",
      "('RT', 145)\n",
      "('a', 114)\n",
      "('to', 103)\n",
      "('the', 103)\n",
      "('with', 101)\n",
      "('The', 73)\n",
      "('you', 71)\n",
      "('health', 66)\n",
      "('of', 64)\n",
      "('in', 56)\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination(timeout=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
